<p align="center">
  <img src="design/icons/app-icon.png" alt="PetGPT Logo" width="128" height="128">
</p>

<h1 align="center">ğŸ¾ PetGPT</h1>

<p align="center">
  <strong>AI Desktop Pet Assistant with Autonomous Social Agent</strong> â€” A lightweight, cross-platform desktop companion powered by large language models, capable of independently participating in group chats.
</p>

---

## ğŸ“¦ Download

**[Download Latest Release â†’](https://github.com/JulesLiu390/PetGPT/tags)**

### macOS Installation

If the app fails to open due to security restrictions, run:

```bash
sudo xattr -cr /Applications/PetGPT.app
```

---

## âœ¨ Features

### ğŸ¤– Multi-LLM Support

Connect to any LLM provider with a unified interface:

- **OpenAI** â€” GPT-4o, GPT-4, GPT-3.5
- **Google Gemini** â€” Official REST API with enhanced multimodal support
- **Anthropic Claude** â€” Claude 3.5 Sonnet, Claude 3 Opus
- **xAI Grok** â€” Grok-2
- **OpenAI-Compatible APIs** â€” Ollama, DeepSeek, or any custom endpoint

### ğŸ¨ Create Your Own AI Companion

Build personalized AI assistants with:

- **Custom Personalities** â€” Define system instructions and behavior
- **Multiple Assistants** â€” Create different characters for different tasks
- **Model Configuration** â€” Separate model settings from assistant personalities
- **Character Appearances** â€” Choose from built-in avatars or create custom ones

### ğŸ˜Š Dynamic Expressions

Characters display real-time emotional reactions:

- **Mood Detection** â€” AI analyzes user messages to determine appropriate mood
- **Expression States** â€” Happy, Normal, Angry expressions
- **Per-Conversation Moods** â€” Each chat session maintains its own mood state

### ğŸ–¼ï¸ Multimodal Support

Rich media capabilities vary by provider:

| Feature | OpenAI | Gemini | Others |
|---------|--------|--------|--------|
| Images | âœ… | âœ… | Varies |
| Video | âŒ | âœ… | âŒ |
| Audio | âŒ | âœ… | âŒ |
| PDF | âŒ | âœ… | âŒ |

- **Paste Images** â€” Directly paste images into chat
- **File Attachments** â€” Upload supported media files
- **Graceful Fallback** â€” Unsupported types convert to text descriptions

### ğŸ”Œ MCP (Model Context Protocol) Integration

Extend AI capabilities with external tools:

- **Stdio Transport** â€” Run local MCP servers (e.g., `npx @modelcontextprotocol/server-*`)
- **HTTP/SSE Transport** â€” Connect to remote MCP endpoints
- **Tool Execution** â€” AI can call tools automatically during conversations
- **Server Management** â€” Start, stop, and configure MCP servers from the UI
- **Per-Conversation Tools** â€” Enable/disable tools per chat session

### ğŸ’¾ Local Memory System

Persistent memory for personalized interactions:

- **Long-Term Memory** â€” AI remembers important user information across sessions
- **Memory Extraction** â€” Automatically identifies and stores key facts (name, preferences, etc.)
- **Per-Assistant Memory** â€” Each assistant maintains separate memory banks
- **Memory Toggle** â€” Enable/disable memory per conversation

### ğŸªŸ Multi-Window Architecture

Flexible desktop integration:

- **Character Window** â€” Always-on-top transparent pet that follows you
- **Chat Window** â€” Resizable chat interface, auto-positions near character
- **Settings Panel** â€” Configure defaults, hotkeys, and preferences
- **MCP Manager** â€” Dedicated window for tool server management
- **Fullscreen Mode** â€” Expand chat with conversation history sidebar
- **Sidebar** â€” Browse and switch between past conversations

### âŒ¨ï¸ Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `Shift + Space` | Toggle character window |
| `Alt + Space` | Toggle chat window |

> Shortcuts are fully customizable in Settings.

### ğŸ—‚ï¸ Conversation Management

- **Multi-Tab Interface** â€” Multiple chat sessions in tabs
- **Conversation History** â€” Full history saved to local SQLite database
- **Session Persistence** â€” Resume conversations after app restart
- **Orphan Recovery** â€” Transfer chats from deleted assistants to new ones

### ğŸ¤ Social Agent â€” Autonomous Group Chat Participation

PetGPT can autonomously join and participate in messaging platform group chats as an independent social agent. Currently supports **QQ** (via [Amadeus-QQ-MCP](https://github.com/JulesLiu390/Amadeus-QQ-MCP)), with **Telegram**, **WhatsApp**, and more platforms planned.

#### Architecture: 4-Layer Processing Pipeline

Each monitored group runs **three independent loops** concurrently:

| Layer | Role | Description |
|-------|------|-------------|
| **Fetcher** | Data Ingestion | Batch-polls all targets on a fixed interval, writes raw messages into a shared in-memory buffer |
| **Observer** | Memory & Archival | Reads the message stream in read-only lurk mode; maintains per-group rule files (`GROUP_RULE_{id}.md`) and a global social memory (`SOCIAL_MEMORY.md`) â€” no sending |
| **Reply** | Response Decision | Detects new messages via watermark comparison; decides whether to speak or stay silent; sends via `send_message` tool call |
| **Intent** | Inner Monologue | Per-group independent thought loop; evaluates the character's subjective reaction to ongoing conversations and outputs a 5-tier willingness score |

#### Intent System â€” 5-Tier Willingness

The Intent loop produces a continuous inner monologue for each group, rating the character's desire to speak:

| Tier | Tag | Meaning |
|------|-----|---------|
| 1 | `[ä¸æƒ³ç†]` | Zero interest, will not speak |
| 2 | `[æ— æ„Ÿ]` | Aware of the topic, but irrelevant |
| 3 | `[æœ‰ç‚¹æƒ³è¯´]` | A thought surfaces, but could stay silent |
| 4 | `[æƒ³èŠ]` | Has something to say, wants to join |
| 5 | `[å¿ä¸ä½]` | Must speak, can't hold back |

Tiers 1â€“2 â†’ sleep (no reply triggered). Tiers 3â€“5 â†’ active (reply loop considers speaking). The intent is injected into the Reply prompt's final user message for maximum recency attention.

#### Lurk Modes

Each target can be independently set to one of three modes:

| Mode | Reply Behavior | Observer | Intent |
|------|---------------|----------|--------|
| `normal` | Full participation | âœ… | Evaluates on every new message |
| `semi-lurk` | Only responds when @mentioned | âœ… | 1-min cooldown between evaluations |
| `full-lurk` | Silent â€” no replies | âœ… | 1-min cooldown between evaluations |

All modes share the same Observer loop for continuous memory archival. Intent prompts are mode-aware â€” the LLM knows whether the character can speak, influencing its thought output.

#### Double-Slot Catchup Queue

Messages arriving while the Reply LLM is running are tracked by a background watcher (2s interval). Up to 2 catchup rounds are queued, ensuring recent messages are not missed without running indefinitely.

#### Platform Support

| Platform | Status | Integration |
|----------|--------|-------------|
| **QQ** | âœ… Supported | Via [Amadeus-QQ-MCP](https://github.com/JulesLiu390/Amadeus-QQ-MCP) (OneBot v11 â†’ native MCP tool calls) |
| **Telegram** | ğŸ”œ Planned | â€” |
| **WhatsApp** | ğŸ”œ Planned | â€” |
| **Discord** | ğŸ”œ Planned | â€” |

---

## ğŸ—‚ï¸ Table of Contents

- [Download](#-download)
- [Features](#-features)
- [Social Agent](#-social-agent--autonomous-group-chat-participation)
- [Keyboard Shortcuts](#ï¸-keyboard-shortcuts)
- [Development Guide](#-development-guide)
- [Project Structure](#-project-structure)
- [Tech Stack](#-tech-stack)
- [License](#-license)

---

## ğŸ§‘â€ğŸ’» Development Guide

### Prerequisites

- **Node.js** 18+
- **Rust** 1.77+ (for Tauri backend)
- **npm** or **pnpm**
- **Platform-specific:**
  - **macOS** â€” Xcode Command Line Tools
  - **Linux** â€” `libwebkit2gtk-4.1-dev`, `libappindicator3-dev`, etc. (see [Tauri prerequisites](https://v2.tauri.app/start/prerequisites/))
  - **Windows** â€” Visual Studio 2022 (MSVC C++ build tools) + Windows SDK

### Setup

```bash
# Install frontend dependencies
npm install
```

### Development

#### macOS / Linux

```bash
npm run tauri:dev
```

#### Windows

> Windows requires a dedicated script to set up the MSVC environment and strip conflicting PATH entries (e.g. Anaconda).

```powershell
npm run tauri:dev:win
```

The `dev-windows.ps1` script automatically cleans the PATH, sets MSVC/SDK environment variables, and starts the dev server.

### Build for Production

#### macOS

```bash
# Build .app bundle
npm run tauri:build

# Build DMG installer (Apple Silicon)
npm run build:dmg

# Build DMG installer (Intel)
sh scripts/create-dmg-intel.sh
```

#### Linux

```bash
# Build .deb package
npm run tauri:build
sh scripts/create-deb.sh
```

#### Windows

```powershell
npm run tauri:build:win
```

The `scripts/build-windows.ps1` script validates prerequisites, configures the MSVC toolchain, and compiles a release build. Output is placed in `src-tauri/target/release/bundle/` (includes `.msi` and NSIS `.exe` installers).

### Build Scripts

| Script | Platform | Description |
|--------|----------|-------------|
| `dev-windows.ps1` | Windows | Set up MSVC environment + start dev server |
| `scripts/build-windows.ps1` | Windows | Set up MSVC environment + release build |
| `scripts/create-dmg.sh` | macOS (ARM) | Package DMG installer |
| `scripts/create-dmg-intel.sh` | macOS (x86) | Package Intel DMG installer |
| `scripts/create-deb.sh` | Linux | Package .deb installer |
| `scripts/generate-all-icons.sh` | macOS | Generate all platform icons from source images |

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ src/                    # React frontend
â”‚   â”œâ”€â”€ components/         # UI components
â”‚   â”‚   â”œâ”€â”€ Chat/           # Chat interface components
â”‚   â”‚   â”œâ”€â”€ Layout/         # Title bars and layout
â”‚   â”‚   â”œâ”€â”€ Settings/       # Settings components
â”‚   â”‚   â””â”€â”€ UI/             # Reusable UI primitives
â”‚   â”œâ”€â”€ context/            # Global state management (Context + Reducer)
â”‚   â”œâ”€â”€ pages/              # Page-level components
â”‚   â””â”€â”€ utils/              # Utilities
â”‚       â”œâ”€â”€ llm/            # LLM adapters (OpenAI, Gemini)
â”‚       â””â”€â”€ mcp/            # MCP tool integration
â”œâ”€â”€ src-tauri/              # Tauri backend (Rust)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ database/       # SQLite data layer
â”‚   â”‚   â””â”€â”€ mcp/            # MCP client implementation
â”‚   â””â”€â”€ tauri.conf.json     # Tauri configuration
â”œâ”€â”€ public/                 # Static assets
â””â”€â”€ package.json
```

### Key Files

| File | Description |
|------|-------------|
| `src-tauri/src/lib.rs` | Tauri commands and app setup |
| `src/utils/bridge.js` | Frontend-backend communication layer |
| `src/utils/llm/` | Unified LLM API adapters |
| `src/components/Chat/ChatboxInputBox.jsx` | Main chat logic |

---

## ğŸ§° Tech Stack

### Desktop Framework

- [**Tauri 2**](https://tauri.app/) â€” Lightweight Rust-based desktop framework
- **SQLite** (via `rusqlite`) â€” Local database for conversations and settings
- **tokio** â€” Async runtime for Rust

### Frontend

- [**React 19**](https://react.dev/) â€” UI framework
- [**Vite**](https://vitejs.dev/) â€” Build tooling
- [**TailwindCSS 4**](https://tailwindcss.com/) â€” Utility-first styling
- [**React Router**](https://reactrouter.com/) â€” Hash-based routing
- [**react-markdown**](https://github.com/remarkjs/react-markdown) â€” Markdown rendering
- [**motion**](https://motion.dev/) â€” Animations

### AI & Tools

- **OpenAI SDK** â€” LLM API client
- **MCP (Model Context Protocol)** â€” Tool/agent framework support
- **Zod** â€” Schema validation

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.
